{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import GraphTextDataset, GraphDataset, TextDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch.utils.data import DataLoader as TorchDataLoader\n",
    "#from Model import Model\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "from torch import optim\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch_geometric.nn import GCNConv, GAT\n",
    "from transformers import AutoModel\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "#from subgraph import subgraph_random_walk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphEncoder(nn.Module):\n",
    "    def __init__(self, num_node_features, nout, nhid, graph_hidden_channels):\n",
    "        super(GraphEncoder, self).__init__()\n",
    "        self.nhid = nhid\n",
    "        self.nout = nout\n",
    "        self.relu = nn.ReLU()\n",
    "        self.ln = nn.LayerNorm((nout))\n",
    "        self.conv1 = GCNConv(num_node_features, graph_hidden_channels)\n",
    "        self.conv2 = GCNConv(graph_hidden_channels, graph_hidden_channels)\n",
    "        self.conv3 = GCNConv(graph_hidden_channels, graph_hidden_channels)\n",
    "        self.mol_hidden1 = nn.Linear(graph_hidden_channels, nhid)\n",
    "        self.mol_hidden2 = nn.Linear(nhid, nout)\n",
    "\n",
    "    def forward(self, graph_batch):\n",
    "        x = graph_batch.x\n",
    "        edge_index = graph_batch.edge_index\n",
    "        batch = graph_batch.batch\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.mol_hidden1(x).relu()\n",
    "        x = self.mol_hidden2(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class GATEncoder(nn.Module):\n",
    "    def __init__(self, nout, nhid, attention_hidden, n_in, dropout):\n",
    "        super(GATEncoder, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.n_in = n_in\n",
    "        self.attention_hidden = attention_hidden\n",
    "        self.n_hidden = nhid\n",
    "        self.n_out = nout\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(self.attention_hidden, self.n_out)\n",
    "        self.GATEnc = GAT(in_channels=self.n_in, hidden_channels = self.attention_hidden, out_channels=self.n_hidden, dropout=self.dropout, num_layers=4, v2=True)\n",
    "\n",
    "    def forward(self, gr):\n",
    "        x = gr.x\n",
    "        x = self.GATEnc(x, gr.edge_index)\n",
    "        x = self.relu(x)\n",
    "        x = global_mean_pool(x, gr.batch)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super(TextEncoder, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        encoded_text = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        return encoded_text.last_hidden_state[:,0,:]\n",
    "    \n",
    "class Model(nn.Module):\n",
    "    def __init__(self, model_name, num_node_features, nout, nhid, graph_hidden_channels):\n",
    "        super(Model, self).__init__()\n",
    "        self.graph_encoder = GraphEncoder(num_node_features, nout, nhid, graph_hidden_channels)\n",
    "        self.text_encoder = TextEncoder(model_name)\n",
    "        \n",
    "    def forward(self, graph_batch, input_ids, attention_mask):\n",
    "        graph_encoded = self.graph_encoder(graph_batch)\n",
    "        text_encoded = self.text_encoder(input_ids, attention_mask)\n",
    "        return graph_encoded, text_encoded\n",
    "    \n",
    "    def get_text_encoder(self):\n",
    "        return self.text_encoder\n",
    "    \n",
    "    def get_graph_encoder(self):\n",
    "        return self.graph_encoder\n",
    "    \n",
    "class ModelGAT(nn.Module):\n",
    "    def __init__(self, model_name, n_in, nout, nhid, attention_hidden, dropout):\n",
    "        super(ModelGAT, self).__init__()\n",
    "        self.graph_encoder = GATEncoder(nout, nhid, attention_hidden, n_in, dropout)\n",
    "        self.text_encoder = TextEncoder(model_name)\n",
    "        \n",
    "    def forward(self, graph_batch, input_ids, attention_mask):\n",
    "        graph_encoded = self.graph_encoder(graph_batch)\n",
    "        text_encoded = self.text_encoder(input_ids, attention_mask)\n",
    "        return graph_encoded, text_encoded\n",
    "    \n",
    "    def get_text_encoder(self):\n",
    "        return self.text_encoder\n",
    "    \n",
    "    def get_graph_encoder(self):\n",
    "        return self.graph_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CE = torch.nn.CrossEntropyLoss()\n",
    "def nt_xent_loss(v1, v2, temp = 1):\n",
    "    logits = torch.matmul(v1,torch.transpose(v2, 0, 1)) / temp \t\n",
    "    labels = torch.arange(logits.shape[0], device=v1.device)\n",
    "    return CE(logits, labels) + CE(torch.transpose(logits, 0, 1), labels)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(vg1, vg2, vt1, vt2, temp = 1):\n",
    "    return (nt_xent_loss(vg1, vt1, temp) + nt_xent_loss(vg2, vt2, temp) + nt_xent_loss(vg1, vt2, temp) + nt_xent_loss(vg2, vt1, temp) + nt_xent_loss(vg1, vg2, temp))/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GraphTextDataset.__init__() got an unexpected keyword argument 'drop'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m GraphTextDataset(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../Public/data/\u001b[39m\u001b[38;5;124m'\u001b[39m, gt\u001b[38;5;241m=\u001b[39mgt, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer)\n\u001b[1;32m      5\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m GraphTextDataset(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../Public/data/\u001b[39m\u001b[38;5;124m'\u001b[39m, gt\u001b[38;5;241m=\u001b[39mgt, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer)\n\u001b[0;32m----> 6\u001b[0m train_drop_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mGraphTextDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../../Public/data/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_drop\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m train_subgraph_dataset \u001b[38;5;241m=\u001b[39m GraphTextDataset(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../Public/data/\u001b[39m\u001b[38;5;124m'\u001b[39m, gt\u001b[38;5;241m=\u001b[39mgt, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_subgraph\u001b[39m\u001b[38;5;124m'\u001b[39m, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer, subgraph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: GraphTextDataset.__init__() got an unexpected keyword argument 'drop'"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = 'distilbert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "gt = np.load(\"../../Public/data/token_embedding_dict.npy\", allow_pickle=True)[()]\n",
    "val_dataset = GraphTextDataset(root='../../Public/data/', gt=gt, split='val', tokenizer=tokenizer)\n",
    "train_dataset = GraphTextDataset(root='../../Public/data/', gt=gt, split='train', tokenizer=tokenizer)\n",
    "train_drop_dataset = GraphTextDataset(root='../../Public/data/', gt=gt, split='train_drop', tokenizer=tokenizer, drop=True)\n",
    "train_subgraph_dataset = GraphTextDataset(root='../../Public/data/', gt=gt, split='train_subgraph', tokenizer=tokenizer, subgraph=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    " \n",
    "nb_epochs = 5\n",
    "batch_size = 32\n",
    "learning_rate = 2e-5\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = ModelGAT(model_name=model_name, n_in=300, nout=768, nhid=1000, attention_hidden=1000, dropout=0.3)\n",
    "#Model(model_name=model_name, num_node_features=300, nout=768, nhid=300, graph_hidden_channels=300) # nout = bert model hidden dim\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate,\n",
    "                                betas=(0.9, 0.999),\n",
    "                                weight_decay=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----EPOCH1-----\n",
      "Iteration: 50, Time: 24.5009 s, training loss: 5.0209\n",
      "Iteration: 100, Time: 48.3899 s, training loss: 4.5705\n",
      "Iteration: 150, Time: 72.9599 s, training loss: 3.9515\n",
      "Iteration: 200, Time: 97.3548 s, training loss: 3.3941\n",
      "Iteration: 250, Time: 121.5333 s, training loss: 3.0376\n",
      "Iteration: 300, Time: 145.8680 s, training loss: 2.7337\n",
      "Iteration: 350, Time: 170.1914 s, training loss: 2.5004\n",
      "Iteration: 400, Time: 194.4660 s, training loss: 2.2695\n",
      "Iteration: 450, Time: 219.1673 s, training loss: 2.1912\n",
      "Iteration: 500, Time: 243.6148 s, training loss: 2.0244\n",
      "Iteration: 550, Time: 268.4169 s, training loss: 1.9669\n",
      "Iteration: 600, Time: 293.0709 s, training loss: 1.8904\n",
      "Iteration: 650, Time: 316.7455 s, training loss: 1.7849\n",
      "Iteration: 700, Time: 341.0838 s, training loss: 1.7672\n",
      "Iteration: 750, Time: 367.1084 s, training loss: 1.6040\n",
      "Iteration: 800, Time: 399.7868 s, training loss: 1.5464\n",
      "-----EPOCH1----- done.  Validation loss:  2.234593241260602\n",
      "validation loss improoved saving checkpoint...\n",
      "checkpoint saved to: ./model0.pt\n",
      "-----EPOCH2-----\n",
      "Iteration: 850, Time: 451.8136 s, training loss: 1.4327\n",
      "Iteration: 900, Time: 476.9545 s, training loss: 1.3509\n",
      "Iteration: 950, Time: 501.9128 s, training loss: 1.4091\n",
      "Iteration: 1000, Time: 526.7332 s, training loss: 1.3909\n",
      "Iteration: 1050, Time: 551.5307 s, training loss: 1.3017\n",
      "Iteration: 1100, Time: 576.2296 s, training loss: 1.2685\n",
      "Iteration: 1150, Time: 600.6269 s, training loss: 1.2009\n",
      "Iteration: 1200, Time: 625.0757 s, training loss: 1.1516\n",
      "Iteration: 1250, Time: 649.8060 s, training loss: 1.1395\n",
      "Iteration: 1300, Time: 674.9910 s, training loss: 1.1534\n",
      "Iteration: 1350, Time: 699.0932 s, training loss: 1.0929\n",
      "Iteration: 1400, Time: 723.2908 s, training loss: 1.1530\n",
      "Iteration: 1450, Time: 747.4710 s, training loss: 1.1051\n",
      "Iteration: 1500, Time: 771.2554 s, training loss: 1.0605\n",
      "Iteration: 1550, Time: 795.3068 s, training loss: 1.0894\n",
      "Iteration: 1600, Time: 819.1050 s, training loss: 1.0520\n",
      "Iteration: 1650, Time: 842.8251 s, training loss: 1.0246\n",
      "-----EPOCH2----- done.  Validation loss:  1.7269454162854414\n",
      "validation loss improoved saving checkpoint...\n",
      "checkpoint saved to: ./model1.pt\n",
      "-----EPOCH3-----\n",
      "Iteration: 1700, Time: 892.1656 s, training loss: 0.9095\n",
      "Iteration: 1750, Time: 916.0780 s, training loss: 0.9321\n",
      "Iteration: 1800, Time: 939.4465 s, training loss: 0.9792\n",
      "Iteration: 1850, Time: 963.1896 s, training loss: 0.9146\n",
      "Iteration: 1900, Time: 996.3344 s, training loss: 0.8984\n",
      "Iteration: 1950, Time: 1025.0915 s, training loss: 0.8805\n",
      "Iteration: 2000, Time: 1049.1199 s, training loss: 0.8587\n",
      "Iteration: 2050, Time: 1073.7675 s, training loss: 0.9075\n",
      "Iteration: 2100, Time: 1097.9420 s, training loss: 0.8420\n",
      "Iteration: 2150, Time: 1122.1588 s, training loss: 0.8381\n",
      "Iteration: 2200, Time: 1147.7972 s, training loss: 0.8226\n",
      "Iteration: 2250, Time: 1172.1275 s, training loss: 0.8161\n",
      "Iteration: 2300, Time: 1196.5344 s, training loss: 0.8680\n",
      "Iteration: 2350, Time: 1221.3883 s, training loss: 0.8203\n",
      "Iteration: 2400, Time: 1245.4854 s, training loss: 0.7518\n",
      "Iteration: 2450, Time: 1269.5568 s, training loss: 0.8261\n",
      "-----EPOCH3----- done.  Validation loss:  1.4231448359787464\n",
      "validation loss improoved saving checkpoint...\n",
      "checkpoint saved to: ./model2.pt\n",
      "-----EPOCH4-----\n",
      "Iteration: 2500, Time: 1317.8370 s, training loss: 0.7250\n",
      "Iteration: 2550, Time: 1343.0923 s, training loss: 0.7069\n",
      "Iteration: 2600, Time: 1366.6918 s, training loss: 0.7609\n",
      "Iteration: 2650, Time: 1390.9856 s, training loss: 0.7033\n",
      "Iteration: 2700, Time: 1415.5204 s, training loss: 0.6737\n",
      "Iteration: 2750, Time: 1440.1292 s, training loss: 0.7428\n",
      "Iteration: 2800, Time: 1465.0673 s, training loss: 0.6655\n",
      "Iteration: 2850, Time: 1489.0915 s, training loss: 0.6611\n",
      "Iteration: 2900, Time: 1512.7016 s, training loss: 0.6769\n",
      "Iteration: 2950, Time: 1536.0046 s, training loss: 0.6281\n",
      "Iteration: 3000, Time: 1559.2452 s, training loss: 0.6670\n",
      "Iteration: 3050, Time: 1587.5705 s, training loss: 0.6863\n",
      "Iteration: 3100, Time: 1619.1450 s, training loss: 0.6628\n",
      "Iteration: 3150, Time: 1644.5518 s, training loss: 0.6651\n",
      "Iteration: 3200, Time: 1668.8338 s, training loss: 0.6402\n",
      "Iteration: 3250, Time: 1693.1100 s, training loss: 0.5890\n",
      "Iteration: 3300, Time: 1717.4329 s, training loss: 0.6591\n",
      "-----EPOCH4----- done.  Validation loss:  1.3243200091215281\n",
      "validation loss improoved saving checkpoint...\n",
      "checkpoint saved to: ./model3.pt\n",
      "-----EPOCH5-----\n",
      "Iteration: 3350, Time: 1765.6000 s, training loss: 0.6135\n",
      "Iteration: 3400, Time: 1790.3386 s, training loss: 0.6565\n",
      "Iteration: 3450, Time: 1814.8427 s, training loss: 0.5743\n",
      "Iteration: 3500, Time: 1839.0733 s, training loss: 0.5947\n",
      "Iteration: 3550, Time: 1863.0640 s, training loss: 0.5591\n",
      "Iteration: 3600, Time: 1887.6887 s, training loss: 0.6196\n",
      "Iteration: 3650, Time: 1911.8382 s, training loss: 0.6050\n",
      "Iteration: 3700, Time: 1936.2334 s, training loss: 0.6619\n",
      "Iteration: 3750, Time: 1960.8679 s, training loss: 0.5551\n",
      "Iteration: 3800, Time: 1985.3971 s, training loss: 0.5763\n",
      "Iteration: 3850, Time: 2009.3906 s, training loss: 0.5490\n",
      "Iteration: 3900, Time: 2033.2679 s, training loss: 0.5747\n",
      "Iteration: 3950, Time: 2059.4043 s, training loss: 0.5963\n",
      "Iteration: 4000, Time: 2091.9173 s, training loss: 0.5342\n",
      "Iteration: 4050, Time: 2118.0549 s, training loss: 0.5290\n",
      "Iteration: 4100, Time: 2140.3311 s, training loss: 0.5689\n",
      "-----EPOCH5----- done.  Validation loss:  1.1039973844129305\n",
      "validation loss improoved saving checkpoint...\n",
      "checkpoint saved to: ./model4.pt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epoch = 0\n",
    "loss = 0\n",
    "losses = []\n",
    "count_iter = 0\n",
    "time1 = time.time()\n",
    "printEvery = 50\n",
    "best_validation_loss = 1000000\n",
    "temp = 1\n",
    "rate = 0.8\n",
    "\n",
    "for i in range(nb_epochs):\n",
    "    print('-----EPOCH{}-----'.format(i+1))\n",
    "    model.train()\n",
    "    for batch, batch_drop, batch_subgraph in zip(train_loader, train_drop_dataset, train_subgraph_dataset):\n",
    "        input_ids = batch.input_ids\n",
    "        batch.pop('input_ids')\n",
    "        attention_mask = batch.attention_mask\n",
    "        batch.pop('attention_mask')\n",
    "        graph_batch = batch\n",
    "\n",
    "        input_ids_drop = batch_drop.input_ids\n",
    "        batch_drop.pop('input_ids')\n",
    "        attention_mask_drop = batch_drop.attention_mask\n",
    "        batch_drop.pop('attention_mask')\n",
    "        graph_batch_drop = batch_drop\n",
    "\n",
    "        input_ids_subgraph = batch_subgraph.input_ids\n",
    "        batch_subgraph.pop('input_ids')\n",
    "        attention_mask_subgraph = batch_subgraph.attention_mask\n",
    "        batch_subgraph.pop('attention_mask')\n",
    "        graph_batch_subgraph = batch_subgraph\n",
    "\n",
    "        \n",
    "        x_graph, x_text = model(graph_batch.to(device), \n",
    "                                input_ids.to(device), \n",
    "                                attention_mask.to(device))\n",
    "        \n",
    "        x_graph_drop, x_text_drop = model(graph_batch_drop.to(device),\n",
    "                                            input_ids_drop.to(device),\n",
    "                                            attention_mask_drop.to(device))\n",
    "        \n",
    "        x_graph_subgraph, x_text_subgraph = model(graph_batch_subgraph.to(device),\n",
    "                                            input_ids_subgraph.to(device),\n",
    "                                            attention_mask_subgraph.to(device))\n",
    "        \n",
    "       \n",
    "        current_loss = contrastive_loss(x_graph_drop, x_graph_subgraph, x_text_drop, x_text_subgraph, temp)\n",
    "        optimizer.zero_grad()\n",
    "        current_loss.backward()\n",
    "        optimizer.step()\n",
    "        loss += current_loss.item()\n",
    "        \n",
    "        count_iter += 1\n",
    "        if count_iter % printEvery == 0:\n",
    "            time2 = time.time()\n",
    "            print(\"Iteration: {0}, Time: {1:.4f} s, training loss: {2:.4f}\".format(count_iter,\n",
    "                                                                        time2 - time1, loss/printEvery))\n",
    "            losses.append(loss)\n",
    "            loss = 0 \n",
    "    model.eval()       \n",
    "    val_loss = 0        \n",
    "    for batch in val_loader:\n",
    "        input_ids = batch.input_ids\n",
    "        batch.pop('input_ids')\n",
    "        attention_mask = batch.attention_mask\n",
    "        batch.pop('attention_mask')\n",
    "        graph_batch = batch\n",
    "        x_graph, x_text = model(graph_batch.to(device), \n",
    "                                input_ids.to(device), \n",
    "                                attention_mask.to(device))\n",
    "        current_loss = contrastive_loss(x_graph, x_graph, x_text, x_text, temp)\n",
    "        val_loss += current_loss.item()\n",
    "    best_validation_loss = min(best_validation_loss, val_loss)\n",
    "    print('-----EPOCH'+str(i+1)+'----- done.  Validation loss: ', str(val_loss/len(val_loader)) )\n",
    "    if best_validation_loss==val_loss:\n",
    "        print('validation loss improoved saving checkpoint...')\n",
    "        save_path = os.path.join('./', 'model'+str(i)+'.pt')\n",
    "        torch.save({\n",
    "        'epoch': i,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'validation_accuracy': val_loss,\n",
    "        'loss': loss,\n",
    "        }, save_path)\n",
    "        print('checkpoint saved to: {}'.format(save_path))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "/home/infres/jalvarez-22/ALTEGRAD/Challenge/Molecule-Retrieval-with-Natural-Language-Queries/src/dataloader.py:145: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3571.)\n",
      "  return torch.LongTensor(edge_index).T, torch.FloatTensor(x)\n",
      "/home/infres/jalvarez-22/ALTEGRAD/Challenge/Molecule-Retrieval-with-Natural-Language-Queries/src/dataloader.py:145: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  return torch.LongTensor(edge_index).T, torch.FloatTensor(x)\n",
      "Done!\n",
      "/home/infres/jalvarez-22/miniconda3/lib/python3.10/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('loading best model...')\n",
    "checkpoint = torch.load(save_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "graph_model = model.get_graph_encoder()\n",
    "text_model = model.get_text_encoder()\n",
    "\n",
    "test_cids_dataset = GraphDataset(root='../../Public/data/', gt=gt, split='test_cids')\n",
    "test_text_dataset = TextDataset(file_path='../../Public/data/test_text.txt', tokenizer=tokenizer)\n",
    "\n",
    "idx_to_cid = test_cids_dataset.get_idx_to_cid()\n",
    "\n",
    "test_loader = DataLoader(test_cids_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "graph_embeddings = []\n",
    "for batch in test_loader:\n",
    "    for output in graph_model(batch.to(device)):\n",
    "        graph_embeddings.append(output.tolist())\n",
    "\n",
    "test_text_loader = TorchDataLoader(test_text_dataset, batch_size=batch_size, shuffle=False)\n",
    "text_embeddings = []\n",
    "for batch in test_text_loader:\n",
    "    for output in text_model(batch['input_ids'].to(device), \n",
    "                             attention_mask=batch['attention_mask'].to(device)):\n",
    "        text_embeddings.append(output.tolist())\n",
    "\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity = cosine_similarity(text_embeddings, graph_embeddings)\n",
    "\n",
    "solution = pd.DataFrame(similarity)\n",
    "solution['ID'] = solution.index\n",
    "solution = solution[['ID'] + [col for col in solution.columns if col!='ID']]\n",
    "solution.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
